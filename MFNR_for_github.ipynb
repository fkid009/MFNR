{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0XCzUT52vxL"
   },
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10042,
     "status": "ok",
     "timestamp": 1709184223870,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "Didp7uN31ghF"
   },
   "outputs": [],
   "source": [
    "# Basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Layer, Input, Flatten, Dense, Embedding, Dropout, Concatenate\n",
    "# from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Mean, RootMeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "# BERT, RoBERTa\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Llxw-UFN2y5C"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1709184223870,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "-L4e9wV22xyc"
   },
   "outputs": [],
   "source": [
    "# For Amazon Data Load\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709184223870,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "L1cCac0Y3tWq"
   },
   "outputs": [],
   "source": [
    "def Load_data(df, user, item, rating, text): # insert variable's name of Data coresponding each variable of function\n",
    "    df = df[[user, item, rating, text]] # extract user ID, item ID, rating, reviewtext\n",
    "    df.rename(columns = {user: \"user\",\n",
    "                        item: \"item\",\n",
    "                        rating: \"rating\",\n",
    "                        text: \"text\"},\n",
    "             inplace = True)\n",
    "\n",
    "    df = df.dropna()\n",
    "    le = LabelEncoder()\n",
    "    df[\"user\"] = le.fit_transform(df[\"user\"].values)\n",
    "    df[\"item\"] = le.fit_transform(df[\"item\"].values)\n",
    "\n",
    "    USER_LEN = df[\"user\"].max() + 1 # number of users\n",
    "    ITEM_LEN = df[\"item\"].max() + 1 # number of items\n",
    "    return df, USER_LEN, ITEM_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709184223871,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "RklPh73b21R2"
   },
   "outputs": [],
   "source": [
    "def Tokenize(data, model_ckpt, batch_size): # function of extracting [CLS] Token embedding from BERT-based model\n",
    "\n",
    "    \"\"\"\n",
    "    model_ckpt: verion of BERT or RoBERTa model\n",
    "    col_name: append cls token embedding data column into dataframe\n",
    "    batch_size: recommend that the value of this variable be 2 or 4\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    model = AutoModel.from_pretrained(model_ckpt).to(device)\n",
    "\n",
    "    embeddings = []\n",
    "    text_list = data['text'].tolist()\n",
    "\n",
    "    for i in tqdm(range(0, len(text_list), batch_size)):\n",
    "        batch_texts = text_list[i:i+batch_size]\n",
    "\n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', truncation=True, padding=True) # default of max_length is 512\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedding = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embeddings.append(embedding.last_hidden_state[:, 0, :])  # append CLS token embedding data\n",
    "\n",
    "    # Stack embeddings into a tensor\n",
    "    stacked_embeddings = torch.cat(embeddings, dim=0)\n",
    "\n",
    "    stacked_embeddings = stacked_embeddings.cpu().numpy()\n",
    "\n",
    "    result = stacked_embeddings.tolist()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709184223871,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "SxmebqCn246V"
   },
   "outputs": [],
   "source": [
    "def bert_roberta(train_df, test_df, batch_size = 1):\n",
    "    global user_grouped, item_grouped\n",
    "    user_grouped = train_df[[\"user\", \"text\"]].groupby('user')[\"text\"].apply(\" \".join).reset_index()\n",
    "    item_grouped = train_df[[\"item\", \"text\"]].groupby('item')[\"text\"].apply(\" \".join).reset_index()\n",
    "\n",
    "    user_grouped[\"user_bert\"] = Tokenize(user_grouped, 'bert-base-uncased', batch_size=batch_size)\n",
    "    item_grouped[\"item_bert\"] = Tokenize(item_grouped, 'bert-base-uncased', batch_size=batch_size)\n",
    "\n",
    "    user_grouped[\"user_roberta\"] = Tokenize(user_grouped, 'roberta-base', batch_size=batch_size)\n",
    "    item_grouped[\"item_roberta\"] = Tokenize(item_grouped, 'roberta-base', batch_size=batch_size)\n",
    "\n",
    "    def group_merge(user_df, item_df, df):\n",
    "        bert_user = pd.merge(df, user_df[[\"user\", \"user_bert\"]], how = \"left\", on  = \"user\")\n",
    "        bert_user_item = pd.merge(bert_user, item_df[[\"item\", \"item_bert\"]], how = \"left\", on  = \"item\")\n",
    "\n",
    "        bert_roberta_user = pd.merge(bert_user_item, user_df[[\"user\", \"user_roberta\"]], how = \"left\", on  = \"user\")\n",
    "        final_df = pd.merge(bert_roberta_user, item_df[[\"item\", \"item_roberta\"]], how = \"left\", on  = \"item\")\n",
    "\n",
    "        return final_df\n",
    "\n",
    "    train_dataset = group_merge(user_grouped, item_grouped, train_df)\n",
    "    test_validation_dataset = group_merge(user_grouped, item_grouped, test_df)\n",
    "\n",
    "    validation_dataset, test_dataset = train_test_split(test_validation_dataset, test_size=0.5, random_state=42)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1709184223871,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "UVuTB91hzm3R"
   },
   "outputs": [],
   "source": [
    "def train_validation_test(dataset):\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # 학습 데이터셋과 테스트 데이터셋 초기화\n",
    "    train_dataset = pd.DataFrame(columns=['user', 'item', 'rating', 'text'])\n",
    "    test_dataset = pd.DataFrame(columns=['user', 'item', 'rating', 'text'])\n",
    "\n",
    "    # 각 유저에 대해 아이템을 8:2로 분할\n",
    "    for user in tqdm(dataset['user'].unique()):\n",
    "        user_data = dataset[dataset['user'] == user]\n",
    "        if len(user_data) > 1:\n",
    "            train, test = train_test_split(user_data, test_size=0.2, random_state=42)\n",
    "            train_dataset = pd.concat([train_dataset, train])\n",
    "            test_dataset = pd.concat([test_dataset, test])\n",
    "        else:\n",
    "            train_dataset = pd.concat([train_dataset, user_data])\n",
    "    test_dataset = test_dataset[test_dataset['item'].isin(train_dataset['item'])]\n",
    "    test_dataset = test_dataset[test_dataset['user'].isin(train_dataset['user'])]\n",
    "    # 결과 출력\n",
    "    print(f\"Train dataset shape: {train_dataset.shape}\")\n",
    "    print(f\"Test dataset shape: {test_dataset.shape}\")\n",
    "\n",
    "    print(set(test_dataset.user).issubset(set(train_dataset.user)))\n",
    "    print(set(test_dataset.item).issubset(set(train_dataset.item)))\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GnH7br76YMaa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMLP\u001b[39;00m(\u001b[43mLayer\u001b[49m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, first_node, n_layer):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28msuper\u001b[39m(MLP, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Layer' is not defined"
     ]
    }
   ],
   "source": [
    "class MLP(Layer):\n",
    "    def __init__(self, first_node, n_layer):\n",
    "        super(MLP, self).__init__()\n",
    "        n_node = first_node\n",
    "        self.mlp_layer = Sequential()\n",
    "        for i in range(n_layer):\n",
    "            self.mlp_layer.add(Dense(units = n_node, activation = \"relu\"))\n",
    "            self.mlp_layer.add(Dropout(0.1))\n",
    "            n_node //= 2\n",
    "\n",
    "    def call(self, input):\n",
    "        x = self.mlp_layer(input)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUzywasrYMab"
   },
   "outputs": [],
   "source": [
    "class MFNR(Model):\n",
    "    def __init__(self, N, M, K):\n",
    "        super(MFNR, self).__init__()\n",
    "        self.user_embedding = Embedding(N, K)\n",
    "        self.item_embedding = Embedding(M, K)\n",
    "        self.user_flatten = Flatten()\n",
    "        self.item_flatten = Flatten()\n",
    "        self.user_nlp_concat = Concatenate()\n",
    "        self.user_nlp_MLP = MLP(512, 4)\n",
    "        self.item_nlp_concat = Concatenate()\n",
    "        self.item_nlp_MLP = MLP(512, 4)\n",
    "        self.user_concat = Concatenate()\n",
    "        self.item_concat = Concatenate()\n",
    "        self.rating_concat = Concatenate()\n",
    "        self.rating_mlp = MLP(64, 3)\n",
    "        self.output_layer =  Dense(1,activation = \"linear\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # User, Item Embedding\n",
    "        user_emb = self.user_embedding(inputs[0])\n",
    "        item_emb = self.item_embedding(inputs[1])\n",
    "        user_emb = self.user_flatten(user_emb)\n",
    "        item_emb = self.item_flatten(item_emb)\n",
    "\n",
    "        # User NLP & MLP\n",
    "        user_nlp = self.user_nlp_concat([inputs[2], inputs[4]])\n",
    "        user_nlp = self.user_nlp_MLP(user_nlp)\n",
    "        # Item NLP\n",
    "        item_nlp = self.item_nlp_concat([inputs[3], inputs[5]])\n",
    "        item_nlp = self.item_nlp_MLP(item_nlp)\n",
    "\n",
    "        # User Representation\n",
    "        user_rep = self.user_concat([user_emb, user_nlp])\n",
    "        # Item Representation\n",
    "        item_rep = self.item_concat([item_emb, item_nlp])\n",
    "\n",
    "        # Rating Prediction\n",
    "        MLP = self.rating_concat([user_rep, item_rep])\n",
    "        MLP = self.rating_mlp(MLP)\n",
    "        output = self.output_layer(MLP)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kchrUy18YMab"
   },
   "outputs": [],
   "source": [
    "def load_metrics():\n",
    "    global train_loss, train_acc\n",
    "    global validation_loss, validation_acc\n",
    "    global test_loss, test_rmse, test_mae\n",
    "\n",
    "    train_loss = Mean()\n",
    "    validation_loss = Mean()\n",
    "    test_loss = Mean()\n",
    "\n",
    "    test_rmse = RootMeanSquaredError()\n",
    "    test_mae = MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyVKa_egYMab"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def trainer():\n",
    "    global train_tfds, train_loss, model\n",
    "    global optimizer, loss_object\n",
    "\n",
    "    for user, item, user_bert, item_bert, user_roberta, item_roberta, y in train_tfds:\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model([user, item, user_bert, item_bert, user_roberta, item_roberta])\n",
    "            loss = loss_object(y, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        train_loss(loss)\n",
    "\n",
    "@tf.function\n",
    "def validation():\n",
    "    global validation_tfds, model, loss_object\n",
    "    global validation_loss, validation_acc\n",
    "    for user, item, user_bert, item_bert, user_roberta, item_roberta, y in validation_tfds:\n",
    "        predictions = model([user, item, user_bert, item_bert, user_roberta, item_roberta])\n",
    "        loss = loss_object(y, predictions)\n",
    "\n",
    "        validation_loss(loss)\n",
    "\n",
    "@tf.function\n",
    "def tester():\n",
    "    global test_tfds, best_model, loss_object\n",
    "    global test_loss, test_rmse, test_mae\n",
    "    for user, item, user_bert, item_bert, user_roberta, item_roberta, y in test_tfds:\n",
    "        predictions = best_model([user, item, user_bert, item_bert, user_roberta, item_roberta])\n",
    "        loss = loss_object(y, predictions)\n",
    "\n",
    "        test_loss(loss)\n",
    "        test_rmse(y, predictions)\n",
    "        test_mae(y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9LMTqb03nfs"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 1242,
     "status": "ok",
     "timestamp": 1709184225099,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "3z3zlVli3XiB"
   },
   "outputs": [],
   "source": [
    "df = getDF('./Subscription_Boxes.jsonl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 6664,
     "status": "ok",
     "timestamp": 1709184231759,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "mmq7Np4h3p8W",
    "outputId": "2e843be2-8d66-44de-9e17-062e99d11c9b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>USELESS</td>\n",
       "      <td>Absolutely useless nonsense and a complete was...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07G584SHG</td>\n",
       "      <td>B09WC47S3V</td>\n",
       "      <td>AEMJ2EG5ODOCYUTI54NBXZHDJGSQ</td>\n",
       "      <td>1602133857705</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Manufactured where?</td>\n",
       "      <td>With a couple of the items, I wasn't quite sur...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07QL1JRCN</td>\n",
       "      <td>B07QL1JRCN</td>\n",
       "      <td>AEEJBFZKUBEEMBZUZJV4UHFVEEBQ</td>\n",
       "      <td>1609110735433</td>\n",
       "      <td>20</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Little bang for your buck.</td>\n",
       "      <td>Two SMALL stuffed animals and 2 little bags of...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07RBYJN37</td>\n",
       "      <td>B08N5QKX1Y</td>\n",
       "      <td>AGSVZNZBTSGQBKZDZTQYEZHGDPCQ</td>\n",
       "      <td>1609937315319</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>New favorite box</td>\n",
       "      <td>Although I don’t remember signing up for this,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07KM6T8GV</td>\n",
       "      <td>B07KM6T8GV</td>\n",
       "      <td>AFDERNB6BIR3U2DOR3S2KX7KJJXQ</td>\n",
       "      <td>1616156351887</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Coctique</td>\n",
       "      <td>I loved every thing and could use it all. Thin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07NVL6TJG</td>\n",
       "      <td>B07NVKNVNM</td>\n",
       "      <td>AE6P2YJ6FKX332MD56GPJFSHXNJQ</td>\n",
       "      <td>1559533206066</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                       title  \\\n",
       "0     1.0                     USELESS   \n",
       "1     2.0         Manufactured where?   \n",
       "2     1.0  Little bang for your buck.   \n",
       "3     5.0            New favorite box   \n",
       "4     5.0                    Coctique   \n",
       "\n",
       "                                                text images        asin  \\\n",
       "0  Absolutely useless nonsense and a complete was...     []  B07G584SHG   \n",
       "1  With a couple of the items, I wasn't quite sur...     []  B07QL1JRCN   \n",
       "2  Two SMALL stuffed animals and 2 little bags of...     []  B07RBYJN37   \n",
       "3  Although I don’t remember signing up for this,...     []  B07KM6T8GV   \n",
       "4  I loved every thing and could use it all. Thin...     []  B07NVL6TJG   \n",
       "\n",
       "  parent_asin                       user_id      timestamp  helpful_vote  \\\n",
       "0  B09WC47S3V  AEMJ2EG5ODOCYUTI54NBXZHDJGSQ  1602133857705             2   \n",
       "1  B07QL1JRCN  AEEJBFZKUBEEMBZUZJV4UHFVEEBQ  1609110735433            20   \n",
       "2  B08N5QKX1Y  AGSVZNZBTSGQBKZDZTQYEZHGDPCQ  1609937315319             4   \n",
       "3  B07KM6T8GV  AFDERNB6BIR3U2DOR3S2KX7KJJXQ  1616156351887             1   \n",
       "4  B07NVKNVNM  AE6P2YJ6FKX332MD56GPJFSHXNJQ  1559533206066             0   \n",
       "\n",
       "   verified_purchase  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  \n",
       "3               True  \n",
       "4               True  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1709184231759,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "YaW32ei5DnR_",
    "outputId": "cac2872f-07bb-4979-9f83-3e1788cfc628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 77071 entries, 0 to 77070\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   overall         77071 non-null  float64\n",
      " 1   verified        77071 non-null  bool   \n",
      " 2   reviewTime      77071 non-null  object \n",
      " 3   reviewerID      77071 non-null  object \n",
      " 4   asin            77071 non-null  object \n",
      " 5   style           36037 non-null  object \n",
      " 6   reviewerName    77044 non-null  object \n",
      " 7   reviewText      77060 non-null  object \n",
      " 8   summary         77061 non-null  object \n",
      " 9   unixReviewTime  77071 non-null  int64  \n",
      " 10  vote            9620 non-null   object \n",
      " 11  image           1719 non-null   object \n",
      "dtypes: bool(1), float64(1), int64(1), object(9)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1709184232329,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "jgmZ77Px3qgM",
    "outputId": "37bb616f-3bc2-4b00-d721-6c77345551ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-6c02a1d01fab>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns = {user: \"user\",\n"
     ]
    }
   ],
   "source": [
    "df, USER_LEN, ITEM_LEN = Load_data(df, \"reviewerID\", \"asin\", \"overall\", \"reviewText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1709184232329,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "3lfC2yqi3wAg",
    "outputId": "537bd46e-718b-4356-d6e5-e3559d01ab99"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df\",\n  \"rows\": 77060,\n  \"fields\": [\n    {\n      \"column\": \"user\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3180,\n        \"min\": 0,\n        \"max\": 11040,\n        \"num_unique_values\": 11041,\n        \"samples\": [\n          406,\n          9402,\n          582\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"item\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1545,\n        \"min\": 0,\n        \"max\": 5333,\n        \"num_unique_values\": 5334,\n        \"samples\": [\n          1200,\n          4461,\n          3160\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9496358543956189,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.0,\n          2.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 58330,\n        \"samples\": [\n          \"I had some extra money and i always wanted to buy a 3d printer for my personal use and to keep at work for the occasional prototype.  I have an engineering/machining background.  I also have experience in 3D printing due to a course i had in college.  Our machines were much higher-end machines (Stratasys and OBJET) so i knew about file formats and slicing. This is my first experience however with a consumer grade machine and i am deeply enjoying a challenge.\\n\\nThe Problems:\\nWhen i first received the package, i took an inventory and i found nothing was missing.  I did find one of the support legs of the main frame had a chip out of the plexiglass.  Quick email to support@reprapguru.com and the part is on its way.  These things happen and i am more than satisfied with how it was handled.\\n\\nAnother problem i had was when i plugged in the Ramps 1.4 board, the Arduino would shut off and would send an alert to my computer that it was drawing too much power.  I double checked that my limit switches were oriented correctly (Manual makes this perfectly clear you can destroy a voltage regulator on the Arduino Mega if you have them backward.)  I located the problem on one of the switches itself.  The switch had a solder bridge on it so it was shorting two pins together.  Thankfully my board wasn't destroyed.\\n\\nFinally, i wish the printer came with tech-flex so that we can tame the medusa of wires after all the connections are made.\\n\\nThe good:\\nThis machine is infinitely adaptable and if you understand the process... quite capable of excellent print quality.  I bought it hoping it wouldn't require too much tweaking (i don't like unnecessary tweaking) but understand it is a necessary evil sometimes.  This machine has brought it to a manageable level.  If you have no desire to troubleshoot or find it hard to think critically to why a problem has arisen, maybe try another machine.  If you follow the directions though, you will be very close to what you need to get up and running.  I am very glad i purchased this machine vs. a davinci jr.\\n\\nSetup:\\nIt took me about 8 hours total from unboxing to printing.  Again i am an engineer who understands how limit switches, controllers, and stepper motors interface.  The instructions are thorough enough for a beginner, just don't be in a rush or get frustrated if you have a couple quirks to work out.  I will be buying another if i find i need more machine capacity.\\n\\nUpdate: 5/13/16\\nThis review was done of my own free will to help others make decisions on going with this seller and printer.  I did receive a roll of Black PLA after it was written from the company.\",\n          \"The spool I received was an average thickness of 1.75, a tad over and a tad under in places. Printed well at a range of temperatures but I personally used it between 200-208. Prints looked nice. The filament did cross itself several times while being unspooled which sometimes needed manual intervention. I recommend unrolling a decent section of it before any print you won't be monitoring for a while just to be safe. Will buy again.\",\n          \"Exactly as described. This item was was well packaged, shipped and received promptly, and was exactly as described. This is a good product and was good customer service.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-52f7d956-bc71-4301-a8b1-133b10eeb48f\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1557</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This worked really well for what I used it for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4282</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Fast cutting and good adheasive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7415</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Worked great for my lapping bench.  I would li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10602</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>As advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2574</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>seems like a pretty good value as opposed to b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52f7d956-bc71-4301-a8b1-133b10eeb48f')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-52f7d956-bc71-4301-a8b1-133b10eeb48f button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-52f7d956-bc71-4301-a8b1-133b10eeb48f');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-5e83a6b6-edf2-4104-b64c-411f4b7ed748\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e83a6b6-edf2-4104-b64c-411f4b7ed748')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-5e83a6b6-edf2-4104-b64c-411f4b7ed748 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "    user  item  rating                                               text\n",
       "0   1557     0     5.0  This worked really well for what I used it for...\n",
       "1   4282     0     5.0                   Fast cutting and good adheasive.\n",
       "2   7415     0     5.0  Worked great for my lapping bench.  I would li...\n",
       "3  10602     1     4.0                                      As advertised\n",
       "4   2574     1     5.0  seems like a pretty good value as opposed to b..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 46801,
     "status": "ok",
     "timestamp": 1709184279124,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "QkYsnbth3xTe",
    "outputId": "2b6d9389-18e3-4a60-df42-536ff326f544"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11041/11041 [00:46<00:00, 236.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (57957, 4)\n",
      "Test dataset shape: (19068, 4)\n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_validation_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 737489,
     "status": "ok",
     "timestamp": 1709185016600,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "FH_VSfoj58ZU",
    "outputId": "43805d6f-c705-4aad-c1cf-5354b36de08b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5521/5521 [03:46<00:00, 24.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2662/2662 [02:27<00:00, 18.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 5521/5521 [03:37<00:00, 25.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 2662/2662 [02:19<00:00, 19.14it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds, validation_ds, test_ds = bert_roberta(train_df, test_df, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 9816,
     "status": "ok",
     "timestamp": 1709185028168,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "VjCHdkDbHnb_"
   },
   "outputs": [],
   "source": [
    "train_dict = {\"train_user\": train_ds[\"user\"].values.astype(np.float32),\n",
    "              \"train_item\": train_ds[\"item\"].values.astype(np.float32),\n",
    "              \"train_user_bert\": np.array(train_ds[\"user_bert\"].tolist()),\n",
    "              \"train_item_bert\": np.array(train_ds[\"item_bert\"].tolist()),\n",
    "              \"train_user_roberta\": np.array(train_ds[\"user_roberta\"].tolist()),\n",
    "              \"train_item_roberta\": np.array(train_ds[\"item_roberta\"].tolist()),\n",
    "              \"train_y\": train_ds[\"rating\"].values.astype(np.float32)}\n",
    "\n",
    "validation_dict = {\"validation_user\": validation_ds[\"user\"].values.astype(np.float32),\n",
    "              \"validation_item\": validation_ds[\"item\"].values.astype(np.float32),\n",
    "              \"validation_user_bert\": np.array(validation_ds[\"user_bert\"].tolist()),\n",
    "              \"validation_item_bert\": np.array(validation_ds[\"item_bert\"].tolist()),\n",
    "              \"validation_user_roberta\": np.array(validation_ds[\"user_roberta\"].tolist()),\n",
    "              \"validation_item_roberta\": np.array(validation_ds[\"item_roberta\"].tolist()),\n",
    "              \"validation_y\": validation_ds[\"rating\"].values.astype(np.float32)}\n",
    "\n",
    "test_dict = {\"test_user\": test_ds[\"user\"].values.astype(np.float32),\n",
    "              \"test_item\": test_ds[\"item\"].values.astype(np.float32),\n",
    "              \"test_user_bert\": np.array(test_ds[\"user_bert\"].tolist()),\n",
    "              \"test_item_bert\": np.array(test_ds[\"item_bert\"].tolist()),\n",
    "              \"test_user_roberta\": np.array(test_ds[\"user_roberta\"].tolist()),\n",
    "              \"test_item_roberta\": np.array(test_ds[\"item_roberta\"].tolist()),\n",
    "              \"test_y\": test_ds[\"rating\"].values.astype(np.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4085,
     "status": "ok",
     "timestamp": 1709185032240,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "E_uYpq_DKw0K"
   },
   "outputs": [],
   "source": [
    "train_tfds = tf.data.Dataset.from_tensor_slices((train_dict[\"train_user\"], train_dict[\"train_item\"],\n",
    "                                               train_dict[\"train_user_bert\"], train_dict[\"train_item_bert\"],\n",
    "                                               train_dict[\"train_user_roberta\"], train_dict[\"train_item_roberta\"],\n",
    "                                               train_dict[\"train_y\"]))\n",
    "train_tfds = train_tfds.shuffle(1000).batch(1024)\n",
    "\n",
    "validation_tfds = tf.data.Dataset.from_tensor_slices((validation_dict[\"validation_user\"], validation_dict[\"validation_item\"],\n",
    "                                                    validation_dict[\"validation_user_bert\"], validation_dict[\"validation_item_bert\"],\n",
    "                                                    validation_dict[\"validation_user_roberta\"], validation_dict[\"validation_item_roberta\"],\n",
    "                                                    validation_dict[\"validation_y\"]))\n",
    "validation_tfds = validation_tfds.shuffle(1000).batch(512)\n",
    "\n",
    "test_tfds = tf.data.Dataset.from_tensor_slices((test_dict[\"test_user\"], test_dict[\"test_item\"],\n",
    "                                              test_dict[\"test_user_bert\"], test_dict[\"test_item_bert\"],\n",
    "                                              test_dict[\"test_user_roberta\"], test_dict[\"test_item_roberta\"],\n",
    "                                              test_dict[\"test_y\"]))\n",
    "test_tfds = test_tfds.shuffle(1000).batch(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QRJnVCnK-Fv"
   },
   "source": [
    "# Initiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1709185032241,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "DhNOv_NPK_EV"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "LR = 0.001\n",
    "\n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = Adam(learning_rate = LR)\n",
    "\n",
    "load_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tBo0saE3LB8V"
   },
   "source": [
    "# Model Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1709185032241,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "_tbnx10tLHTR"
   },
   "outputs": [],
   "source": [
    "model = MFNR(USER_LEN, ITEM_LEN, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101536,
     "status": "ok",
     "timestamp": 1709185133772,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "RNQAzQbnLNrW",
    "outputId": "42232452-9eac-4986-e35e-8348e27ad0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train_loss: 2.080, validation_loss: 0.855\n",
      "\n",
      "Model Save!\n",
      "\n",
      "Epoch: 1\n",
      "train_loss: 0.781, validation_loss: 0.787\n",
      "\n",
      "Model Save!\n",
      "\n",
      "Epoch: 2\n",
      "train_loss: 0.634, validation_loss: 0.773\n",
      "\n",
      "Model Save!\n",
      "\n",
      "Epoch: 3\n",
      "train_loss: 0.556, validation_loss: 0.845\n",
      "\n",
      "num: 1\n",
      "\n",
      "Epoch: 4\n",
      "train_loss: 0.626, validation_loss: 0.910\n",
      "\n",
      "num: 2\n",
      "\n",
      "Epoch: 5\n",
      "train_loss: 0.678, validation_loss: 0.830\n",
      "\n",
      "num: 3\n",
      "\n",
      "Epoch: 6\n",
      "train_loss: 0.813, validation_loss: 0.970\n",
      "\n",
      "num: 4\n",
      "\n",
      "Epoch: 7\n",
      "train_loss: 0.981, validation_loss: 0.791\n",
      "\n",
      "num: 5\n",
      "early stopping\n"
     ]
    }
   ],
   "source": [
    "loss_list = []\n",
    "num = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    trainer()\n",
    "    validation()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    print(f'train_loss: {(train_loss.result()):.3f}, validation_loss: {(validation_loss.result()):.3f}\\n')\n",
    "\n",
    "    loss_list.append(validation_loss.result())\n",
    "    min_loss = np.min(loss_list)\n",
    "\n",
    "    if validation_loss.result() <= min_loss:\n",
    "        print(\"Model Save!\")\n",
    "        num = 0\n",
    "        best_model = model\n",
    "    else:\n",
    "        num += 1\n",
    "        print(f\"num: {num}\")\n",
    "        if num == 5:\n",
    "            print(\"early stopping\")\n",
    "            break\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    validation_loss.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 790,
     "status": "ok",
     "timestamp": 1709185134549,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "v6w2WQKZQU56",
    "outputId": "90227f91-754d-4c2f-c76f-249b43302250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_loss: 0.777\n",
      "Test_rmse: 0.883\n",
      "Test_mae: 0.605\n"
     ]
    }
   ],
   "source": [
    "tester()\n",
    "print(f'Test_loss: {(test_loss.result()):.3f}')\n",
    "print(f'Test_rmse: {(test_rmse.result()):.3f}')\n",
    "print(f'Test_mae: {(test_mae.result()):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1709185134550,
     "user": {
      "displayName": "임해빈",
      "userId": "11652320193016134538"
     },
     "user_tz": -540
    },
    "id": "hkG5FZGrT-7S"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMWz4GOVFc41r4piq+El88i",
   "gpuType": "T4",
   "mount_file_id": "1Pgq8kofMWyaaLpncNKWVq-o-OVDrO37e",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "press9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
